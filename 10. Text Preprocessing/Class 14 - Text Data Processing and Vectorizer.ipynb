{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49cfd5b6",
   "metadata": {},
   "source": [
    "# Stemming in NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b98e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "nltk.download('punkt')  # Download the required resource (tokenizer models) \n",
    "#!pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a5b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = ['change','changing','changes','changed'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "622902d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['change', 'changing', 'changes', 'changed']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3025ab6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rashe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53806986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f56cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be1b987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change chang\n",
      "changing chang\n",
      "changes chang\n",
      "changed chang\n"
     ]
    }
   ],
   "source": [
    "for w in word:\n",
    "    print(w, p.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd2eed15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change chang\n",
      "changing chang\n",
      "changes chang\n",
      "changed chang\n"
     ]
    }
   ],
   "source": [
    "for w in word:\n",
    "    print(w , p.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e1eb61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = 'I want to change the world if world changed my career by changing abcd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f8aeb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to change the world if world changed my career by changing abcd'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad049b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4891a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "toke = word_tokenize(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31e33432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'want',\n",
       " 'to',\n",
       " 'change',\n",
       " 'the',\n",
       " 'world',\n",
       " 'if',\n",
       " 'world',\n",
       " 'changed',\n",
       " 'my',\n",
       " 'career',\n",
       " 'by',\n",
       " 'changing',\n",
       " 'abcd']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18559d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'want',\n",
       " 'to',\n",
       " 'change',\n",
       " 'the',\n",
       " 'world',\n",
       " 'if',\n",
       " 'world',\n",
       " 'changed',\n",
       " 'my',\n",
       " 'career',\n",
       " 'by',\n",
       " 'changing',\n",
       " 'abcd']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e9e000f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I i\n",
      "want want\n",
      "to to\n",
      "change chang\n",
      "the the\n",
      "world world\n",
      "if if\n",
      "world world\n",
      "changed chang\n",
      "my my\n",
      "career career\n",
      "by by\n",
      "changing chang\n",
      "abcd abcd\n"
     ]
    }
   ],
   "source": [
    "for w in toke:\n",
    "    print(w , p.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be84d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347deea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13a690",
   "metadata": {},
   "source": [
    "# Lemmatization in NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35256907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83e06afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86b11cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'want',\n",
       " 'to',\n",
       " 'change',\n",
       " 'the',\n",
       " 'world',\n",
       " 'if',\n",
       " 'world',\n",
       " 'changed',\n",
       " 'my',\n",
       " 'career',\n",
       " 'by',\n",
       " 'changing',\n",
       " 'abcd']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cd80d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I\n",
      "want want\n",
      "to to\n",
      "change change\n",
      "the the\n",
      "world world\n",
      "if if\n",
      "world world\n",
      "changed changed\n",
      "my my\n",
      "career career\n",
      "by by\n",
      "changing changing\n",
      "abcd abcd\n"
     ]
    }
   ],
   "source": [
    "for w in toke:\n",
    "    print(w , le.lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e6dda9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'change'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.lemmatize('changes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ecd2a",
   "metadata": {},
   "source": [
    "# Tokenization in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bc5e77",
   "metadata": {},
   "source": [
    "In Python, there are several libraries and tools available for performing tokenization and other NLP tasks. Here are a few examples using popular libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b22c7e",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ecf14",
   "metadata": {},
   "source": [
    "NLTK (Natural Language Toolkit) is a widely used library for NLP tasks. To perform tokenization using NLTK, you need to install it first. You can do so by running pip install nltk. Here's an example of tokenizing a sentence using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c0265a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'m\", 'from', 'aiQuest', 'Intelligence', '.', 'I', 'am', 'learning', 'NLP', '.', 'It', 'is', 'fascinating', '!']\n",
      "[\"I'm from aiQuest Intelligence.\", 'I am learning NLP.', 'It is fascinating!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "sentence = \"I'm from aiQuest Intelligence. I am learning NLP. It is fascinating!\"\n",
    "word_tokens = word_tokenize(sentence)\n",
    "sentence_tokens = sent_tokenize(sentence)\n",
    "\n",
    "print(word_tokens)\n",
    "print(sentence_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3707c60",
   "metadata": {},
   "source": [
    "# spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c406d7",
   "metadata": {},
   "source": [
    "spaCy is another powerful library for NLP. To install spaCy, you can run pip install spacy and then download the appropriate language model. Here's an example of tokenization using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17526b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "# python -m spacy download en_core_web_sm    -> install in conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42130eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'m\", 'from', 'aiQuest', 'Intelligence', '.', 'I', 'am', 'learning', 'NLP', '.', 'It', 'is', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')  # Load the English language model\n",
    "\n",
    "sentence = \"I'm from aiQuest Intelligence. I am learning NLP. It is fascinating!\"\n",
    "doc = nlp(sentence)\n",
    "\n",
    "word_tokens = [token.text for token in doc]\n",
    "\n",
    "print(word_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae4db8d",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7932f5",
   "metadata": {},
   "source": [
    "Transformers is a library built by Hugging Face that provides state-of-the-art pre-trained models for NLP. It offers various functionalities, including tokenization. To install Transformers, run pip install transformers. Here's an example of tokenization using Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef052805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"'\", 'm', 'from', 'ai', '##quest', 'intelligence', '.', 'i', 'am', 'learning', 'nl', '##p', '.', 'it', 'is', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "sentence = \"I'm from aiQuest Intelligence. I am learning NLP. It is fascinating!\"\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a12b3",
   "metadata": {},
   "source": [
    "# Named Entity Tokenization using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3747ac00",
   "metadata": {},
   "source": [
    "To perform named entity tokenization using NLTK (Natural Language Toolkit), you can utilize the named entity recognition (NER) functionality provided by NLTK. Here's an example of how to extract named entity tokens from a sentence using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "108ede5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\rashe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43e1d062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rashe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f061a0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aiQuest Intelligence', 'NLP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\rashe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\rashe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')  # Download the required resource (NER models)\n",
    "nltk.download('words')  # Download the required resource (word corpus) \n",
    "\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "sentence = \"I'm from aiQuest Intelligence. I am learning NLP. It is fascinating!\"\n",
    "\n",
    "# Tokenize the sentence into words\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "pos_tags = pos_tag(tokens)\n",
    "\n",
    "# Perform named entity recognition\n",
    "ner_tags = ne_chunk(pos_tags) \n",
    "\n",
    "# Extract named entity tokens\n",
    "named_entity_tokens = []\n",
    "\n",
    "for chunk in ner_tags:\n",
    "    if hasattr(chunk, 'label'): #hasattr(object, attribute)\n",
    "        \n",
    "        named_entity_tokens.append(' '.join(c[0] for c in chunk))\n",
    "\n",
    "print(named_entity_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa3fd7a",
   "metadata": {},
   "source": [
    "# Text Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "debf601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca4bfa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love Bangladesh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you give me an iphone?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello how are you?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to talk you.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           test  class\n",
       "0             I love Bangladesh      1\n",
       "1  Could you give me an iphone?      0\n",
       "2            Hello how are you?      1\n",
       "3           I want to talk you.      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a25fbe5",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0a3791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd44238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "553a30d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x14 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_x = cv.fit_transform(df['test'])\n",
    "cv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "431cff4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a40be879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " 'are',\n",
       " 'bangladesh',\n",
       " 'could',\n",
       " 'give',\n",
       " 'hello',\n",
       " 'how',\n",
       " 'iphone',\n",
       " 'love',\n",
       " 'me',\n",
       " 'talk',\n",
       " 'to',\n",
       " 'want',\n",
       " 'you']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "698d461a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>are</th>\n",
       "      <th>bangladesh</th>\n",
       "      <th>could</th>\n",
       "      <th>give</th>\n",
       "      <th>hello</th>\n",
       "      <th>how</th>\n",
       "      <th>iphone</th>\n",
       "      <th>love</th>\n",
       "      <th>me</th>\n",
       "      <th>talk</th>\n",
       "      <th>to</th>\n",
       "      <th>want</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   an  are  bangladesh  could  give  hello  how  iphone  love  me  talk  to  \\\n",
       "0   0    0           1      0     0      0    0       0     1   0     0   0   \n",
       "1   1    0           0      1     1      0    0       1     0   1     0   0   \n",
       "2   0    1           0      0     0      1    1       0     0   0     0   0   \n",
       "3   0    0           0      0     0      0    0       0     0   0     1   1   \n",
       "\n",
       "   want  you  \n",
       "0     0    0  \n",
       "1     0    1  \n",
       "2     0    1  \n",
       "3     1    1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(cv_x.toarray(), columns=cv.get_feature_names())\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "680ed45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(cv_x.toarray(), columns=cv.get_feature_names(), index=df['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1c27935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>are</th>\n",
       "      <th>bangladesh</th>\n",
       "      <th>could</th>\n",
       "      <th>give</th>\n",
       "      <th>hello</th>\n",
       "      <th>how</th>\n",
       "      <th>iphone</th>\n",
       "      <th>love</th>\n",
       "      <th>me</th>\n",
       "      <th>talk</th>\n",
       "      <th>to</th>\n",
       "      <th>want</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I love Bangladesh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Could you give me an iphone?</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hello how are you?</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I want to talk you.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              an  are  bangladesh  could  give  hello  how  \\\n",
       "test                                                                         \n",
       "I love Bangladesh              0    0           1      0     0      0    0   \n",
       "Could you give me an iphone?   1    0           0      1     1      0    0   \n",
       "Hello how are you?             0    1           0      0     0      1    1   \n",
       "I want to talk you.            0    0           0      0     0      0    0   \n",
       "\n",
       "                              iphone  love  me  talk  to  want  you  \n",
       "test                                                                 \n",
       "I love Bangladesh                  0     1   0     0   0     0    0  \n",
       "Could you give me an iphone?       1     0   1     0   0     0    1  \n",
       "Hello how are you?                 0     0   0     0   0     0    1  \n",
       "I want to talk you.                0     0   0     1   1     1    1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5fd34",
   "metadata": {},
   "source": [
    "# TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29a5e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "374ce011",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_z = tf.fit_transform(df['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db374268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x14 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32dc4e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(tf_z.toarray(), columns=tf.get_feature_names(), index=df['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a0e7c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>are</th>\n",
       "      <th>bangladesh</th>\n",
       "      <th>could</th>\n",
       "      <th>give</th>\n",
       "      <th>hello</th>\n",
       "      <th>how</th>\n",
       "      <th>iphone</th>\n",
       "      <th>love</th>\n",
       "      <th>me</th>\n",
       "      <th>talk</th>\n",
       "      <th>to</th>\n",
       "      <th>want</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I love Bangladesh</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Could you give me an iphone?</th>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hello how are you?</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I want to talk you.</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.345783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    an       are  bangladesh     could  \\\n",
       "test                                                                     \n",
       "I love Bangladesh             0.000000  0.000000    0.707107  0.000000   \n",
       "Could you give me an iphone?  0.430037  0.000000    0.000000  0.430037   \n",
       "Hello how are you?            0.000000  0.541736    0.000000  0.000000   \n",
       "I want to talk you.           0.000000  0.000000    0.000000  0.000000   \n",
       "\n",
       "                                  give     hello       how    iphone  \\\n",
       "test                                                                   \n",
       "I love Bangladesh             0.000000  0.000000  0.000000  0.000000   \n",
       "Could you give me an iphone?  0.430037  0.000000  0.000000  0.430037   \n",
       "Hello how are you?            0.000000  0.541736  0.541736  0.000000   \n",
       "I want to talk you.           0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                  love        me      talk        to  \\\n",
       "test                                                                   \n",
       "I love Bangladesh             0.707107  0.000000  0.000000  0.000000   \n",
       "Could you give me an iphone?  0.000000  0.430037  0.000000  0.000000   \n",
       "Hello how are you?            0.000000  0.000000  0.000000  0.000000   \n",
       "I want to talk you.           0.000000  0.000000  0.541736  0.541736   \n",
       "\n",
       "                                  want       you  \n",
       "test                                              \n",
       "I love Bangladesh             0.000000  0.000000  \n",
       "Could you give me an iphone?  0.000000  0.274487  \n",
       "Hello how are you?            0.000000  0.345783  \n",
       "I want to talk you.           0.541736  0.345783  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e69b187",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fb5a9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\rashe\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\rashe\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\rashe\\anaconda3\\lib\\site-packages (from gensim) (1.21.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\rashe\\anaconda3\\lib\\site-packages (from gensim) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "327f605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1443e1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'love', 'Bangladesh'],\n",
       " ['Could', 'you', 'give', 'me', 'an', 'iphone', '?'],\n",
       " ['Hello', 'how', 'are', 'you', '?'],\n",
       " ['I', 'want', 'to', 'talk', 'you', '.']]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vector = [nltk.word_tokenize(test) for test in df['test']]\n",
    "text_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8daabe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(text_vector, min_count=1) #shift+tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a97a89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('an', 0.1782679259777069),\n",
       " ('I', 0.16072483360767365),\n",
       " ('give', 0.10560771077871323),\n",
       " ('how', 0.09215972572565079),\n",
       " ('iphone', 0.04891003668308258),\n",
       " ('are', 0.02700834721326828),\n",
       " ('Could', 0.007729316595941782),\n",
       " ('you', -0.03771639242768288),\n",
       " ('.', -0.045522838830947876),\n",
       " ('talk', -0.04649210348725319)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('want')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f4994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
